{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2806a7e-1ced-420d-94b4-7682f8920da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Arduino ON--------\n",
      "Start measurement\n",
      "End measurement. (2.31sec)\n",
      "measurement for 2.6371729373931885\n",
      "[{'time': 2.6371729373931885, 'pin1': [6, 192, 14, 36, 31, 26], 'pin2': [9, 25, 41, 6, 55, 99, 33]}]\n",
      "Stop\n"
     ]
    }
   ],
   "source": [
    "# measurement\n",
    "\n",
    "import serial\n",
    "import time\n",
    "\n",
    "ser = serial.Serial('COM8', 9600)\n",
    "time.sleep(2)\n",
    "\n",
    "measurements = [] # 측정한 전체 데이터\n",
    "current_data = [] # 측정할 때 사용할 딕셔너리\n",
    "measurement_started = False\n",
    "saving = False\n",
    "try:\n",
    "    while True:\n",
    "        if ser.inWaiting() > 0:\n",
    "\n",
    "            line = ser.readline().decode('utf-8').rstrip() # 데이터 읽기\n",
    "\n",
    "            if \"Arduino\" in line:\n",
    "                print(line)\n",
    "            \n",
    "            if \"Stop\" in line:\n",
    "                print(line)\n",
    "                ser.close()\n",
    "                break\n",
    "            \n",
    "            if \"Start measurement\" in line:\n",
    "                print(line)\n",
    "                measurement_started = True\n",
    "                current_measurement = {\"time\": time.time(), \"pin1\": [], \"pin2\": []}  # 새로운 측정을 위해 초기화\n",
    "            elif \"End measurement\" in line:\n",
    "                print(line)\n",
    "                print(f\"measurement for {time.time() - current_measurement['time']}\")\n",
    "                measurement_started = False\n",
    "                current_measurement[\"time\"] = time.time() - current_measurement[\"time\"]  # 측정 시간 계산\n",
    "                measurements.append(current_measurement)  # 현재 측정 데이터를 전체 리스트에 추가\n",
    "                print(measurements)\n",
    "            elif measurement_started:\n",
    "                if line.startswith(\"pin1: \"):\n",
    "                    value = int(line.split(\": \")[1])\n",
    "                    current_measurement[\"pin1\"].append(value)\n",
    "                elif line.startswith(\"pin2: \"):\n",
    "                    value = int(line.split(\": \")[1])\n",
    "                    current_measurement[\"pin2\"].append(value)\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    ser.close()\n",
    "    print(\"Serial port closed.\")\n",
    "    print(\"Collected data:\", measurements)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dc638b27-5dae-400d-a6a3-a0ea5271f258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예외 떴을 때 사용 (시리얼 통신 끊기)\n",
    "ser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fd53788-c82d-4767-a92d-a9e20628dcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing CustomDataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset, ConcatDataset, DataLoader\n",
    "from custom_dataset import CustomDataset\n",
    "file_name = 'hihi2' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9116d776-23b9-489d-b5a0-7e7d92935d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기존에 데이터셋이 있으므로 기존 데이터셋에 데이터를 추가합니다.\n"
     ]
    }
   ],
   "source": [
    "# save Dataset (기존 데이터셋이 있으면 ConcatDataset 인스턴스로 변경 후 데이터 추가 후 저장, 없으면 새 데이터셋(CustomDataset)을 생성)\n",
    "new_dataSet = CustomDataset(measurements)\n",
    "\n",
    "try:\n",
    "    existing_dataSet = torch.load(file_name + '.pth')\n",
    "    if isinstance(new_dataSet, CustomDataset):\n",
    "        combined_dataSet = ConcatDataset([existing_dataSet, new_dataSet])\n",
    "        print('기존에 데이터셋이 있으므로 기존 데이터셋에 데이터를 추가합니다.')\n",
    "        torch.save(combined_dataSet, file_name + '.pth')\n",
    "    else:\n",
    "        combined_dataSet = new_dataSet\n",
    "        print('기존에 데이터셋은 존재하나 CustomDataset이 아니므로 스킵합니다.')\n",
    "except FileNotFoundError:\n",
    "    combined_dataSet = new_dataSet\n",
    "    print('기존에 데이터셋이 존재하지 않으므로 새로운 데이터셋을 추가합니다.')\n",
    "    torch.save(combined_dataSet, file_name + '.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b338924-b90f-4dbe-ad79-cb74d1d0a93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataset.ConcatDataset object at 0x000001F88C00D350>\n",
      "현재 파일은 CustomDataset의 인스턴스가 아닙니다. CustomDataset으로 변환합니다.\n"
     ]
    }
   ],
   "source": [
    "# ConcatDataset -> CustomDataset으로 변환\n",
    "from torch.utils.data.dataset import ConcatDataset\n",
    "loaded_dataset = torch.load(file_name + '.pth')\n",
    "print(loaded_dataset)\n",
    "if isinstance(loaded_dataset, CustomDataset):\n",
    "    print('현재 파일은 CustomDataset의 인스턴스입니다.')\n",
    "else:\n",
    "    print('현재 파일은 CustomDataset의 인스턴스가 아닙니다. CustomDataset으로 변환합니다.')\n",
    "    # ConcatDataset에 포함된 모든 데이터셋의 요소를 모두 모아 하나의 리스트로 만듬\n",
    "    all_data = []\n",
    "    for data_tuple in loaded_dataset:\n",
    "        data_point = {'time': data_tuple[0], 'pin1': data_tuple[1], 'pin2': data_tuple[2]}\n",
    "        all_data.append(data_point)\n",
    "    \n",
    "    # 새로운 CustomDataset 객체 생성 및 저장\n",
    "    custom_dataset = CustomDataset(all_data)\n",
    "    torch.save(custom_dataset, file_name + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8fa066e-b085-4fc8-bdbb-24c1e122484f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11])\n",
      "Time: tensor([2.6353, 0.4126, 0.4132, 1.7276, 4.9596, 0.4131, 0.4133, 0.4132, 2.6372,\n",
      "        0.4132, 3.7463])\n",
      "Pin1: tensor([[ 90.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [127.,  14.,  17.,  29.,   0.,   0.],\n",
      "        [  6.,  11.,   0.,   0.,   0.,   0.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [  6., 192.,  14.,  36.,  31.,  26.],\n",
      "        [  0.,   0.,   0.,   0.,   0.,   0.],\n",
      "        [ 11.,  10.,  13.,  92.,   0.,   0.]])\n",
      "Pin2: tensor([[63.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [10., 17.,  0.,  0.,  0.,  0.],\n",
      "        [16., 31.,  8.,  5.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 9., 25., 41.,  6., 55., 99.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.]])\n"
     ]
    }
   ],
   "source": [
    "# load Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from padding import PaddingCollate\n",
    "loaded_dataset = torch.load(file_name + '.pth')\n",
    "\n",
    "# DataLoader에 로드된 데이터셋 사용\n",
    "dataloader = DataLoader(loaded_dataset, batch_size=100, shuffle=True, collate_fn=PaddingCollate())\n",
    "for time, pin1, pin2 in dataloader:\n",
    "    print(time.size())\n",
    "    print(\"Time:\", time)\n",
    "    print(\"Pin1:\", pin1)\n",
    "    print(\"Pin2:\", pin2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae7941e-f540-4fe2-b3cf-d64636ff2dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
